name: build test
on: 
  push:
  workflow_dispatch:

jobs:
  hello_world_job:
    runs-on: ubuntu-latest
    name: A job to say hello
    steps:
      - uses: actions/checkout@v4
      - id: foo
        uses: mudler/localai-github-action@v1
        with:
          model: 'hermes-2-theta-llama-3-8b' # Any from models.localai.io, or from huggingface.com with: "huggingface://<repository>/file"
      - run: |
          input="Génére moi un code complet en python qui fait 2+2."
          API_URL="http://localhost:8080/chat/completions"

          json_payload=$(jq -n --arg input "$input" '{
          model: "'$MODEL_NAME'",
          messages: [
            {
            role: "system",
            content: "You are a developer who provides code functional without additional explanations or comments"
            },
            {
            role: "user",
            content: $input
            }
          ]
          }')

          response=$(curl -s -X POST $API_URL -H "Content-Type: application/json" -d "$json_payload")
          result="$(echo $response | jq -r '.choices[0].message.content')"
          echo "Result:"
          echo "$result"
      - name: crewai install 
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          uv tool install crewai
          uv tool list
          crewai version
          uv venv
          uv pip install "crewai[tools]"
      - run: |
          crewai --help
          crewai create crew test55 --skip_provider
          export OPENAI_API_BASE="http://127.0.0.1:8080"
          export OPENAI_API_KEY="test"
          ls -alh
          ls test55
          crewai create crew --help
      - run: |
         cat > ./test55/src/test55/config/agents.yaml <<'EOF'
         agent_createur: 
           role: > 
             chef de projet ia
           goal: > 
             Créer automatiquement une équipe d’agents IA (développeur frontend, backend) 
             pour concevoir et livrer une application web To-Do List complète en Python.
           backstory: > 
             Vous êtes un gestionnaire de projet IA ultra-efficace.
             Vous avez la capacité de recruter dynamiquement les meilleurs agents 
             nécessaires à chaque projet crewai.
             Votre mission : créer et orchestrer une équipe crewai pour produire une 
             application web To-Do List fonctionnelle.
             Toutes les sorties doivent être en français.
           allow_code_execution: True
         EOF
      - run: |
          cat > ./test55/src/test55/config/tasks.yaml <<'EOF'
          equipe_task: 
            description: > 
              1. Génère en utilisant uniquement la bibliothèque crewai ainsi que décorateur crewai (@crewbase, @agent, @task), 
              la configuration complète et fonctionnel d'un equipage multi agent 
              crewai qui créer une apli web To do list en python avec flask sans base de donnée. 
              Cette équipage est avec des agents front un back ayant un rôles et une tâches
              précises.Chaque agent doit avoir un rôle, un objectif (goal), un historique (backstory) 
              et une ou plusieurs tâches avec expected_output. fais cela dans un crew.py. Une fois 
              cela fait dis le.
              2. Lance cet nouvel équipage créer. Termine en imprimant "Équipage 
              créé et lancé avec succès." 
            expected_output: > 
              ecris en francais les commentaire seulement, affiche le code générer 
              ainsi que creer tous les fichiers nécessaires : index.html, 
              app.py, README en français, etc. 
            agent: agent_createur 
          EOF

      - run: |
          cat > ./test55/src/test55/crew.py <<'EOF'
          from crewai import Agent, Crew, Process, Task 
          from crewai.project import CrewBase, agent, crew, task 
          
          @CrewBase
          class Test55():
            """Test55 crew"""

            agents_config = "config/agents.yaml"
            tasks_config = "config/tasks.yaml"

            @agent
            def agent_createur(self) -> Agent:
              return Agent(
                config=self.agents_config['agent_createur'],
                verbose=True
             )

            
            # To learn more about structured task outputs,
            # task dependencies, and task callbacks, check out the documentation:
            # https://docs.crewai.com/concepts/tasks#overview-of-a-task

            @task
            def reporting_task(self) -> Task:
              return Task(
                config=self.tasks_config['equipe_task'],
             )

            @crew
            def crew(self) -> Crew:
              """Creates the Test55 crew"""
              return Crew(
                agents=self.agents,  # Chargé automatiquement depuis le YAML
                tasks=self.tasks,    # Chargé automatiquement depuis le YAML
                process=Process.sequential,
                verbose=True,
              )
          EOF

      - run: sudo cat ./test55/README.md
      - run: sudo cat ./test55/src/test55/main.py
      - run: sudo cat ./test55/src/test55/crew.py
      - run: sudo cat ./test55/src/test55/config/agents.yaml
      - run: sudo cat ./test55/src/test55/config/tasks.yaml
      - run: cd test55 && crewai install
      - run: |
          export OPENAI_API_BASE="http://127.0.0.1:8080/v1"
          export OPENAI_API_KEY="test"
          export OPENAI_MODEL_NAME="openai/hermes-2-theta-llama-3-8b"
          cd test55 && crewai run
      - run: ls -alh
      - run: ls -alh test55
      - run: |
          git clone https://github.com/yoheinakajima/babyagi-2o.git
          echo 'clone fait'
          cd babyagi-2o
          python3 -m venv venv
          source venv/bin/activate
          echo 'env virtuel fait'
          pip install litellm
          echo 'install litelm fait'
          export LITELLM_MODEL="localai/hermes-2-theta-llama-3-8b"
    #      echo "creer un script bash que tu va mettre dans un fichier appeler script-b.sh qui va installer k3s" | python main.py
      - run: |
         sudo curl -sS -o spilot_install.sh https://raw.githubusercontent.com/reid41/shell-pilot/main/spilot_install.sh
      - name: Modifier spilot_install.sh pour contourner la validation IP 
        run: | # Commenter la ligne de validation de l'adresse IP dans la fonction add_server_ip 
           sudo sed -i 's/^if \[\[ \$ip_address =~/# if \[\[ \$ip_address =~/' spilot_install.sh
      - name: install Shell pilot 
        run: |
          (echo "127.0.0.1" && echo "127.0.0.1") | sudo bash spilot_install.sh
      - name: config avec localai   
        run: |
          export TERM=dumb
          sudo s-pilot cmp localai
      - name: config avec llama 3 8b
        run: |
          export TERM=dumb
          sudo s-pilot m hermes-2-theta-llama-3-8b
      - run: export TERM=dumb && s-pilot lm
      - run: export TERM=dumb && s-pilot lc
      - run: ls -alh /usr/local/bin/
      - name: Modifier s-pilot pour contourner la confirmation (non dangereux) - Supprimer les lignes
        run: |
          sudo sed -i '/elif [[ "$DANGER_CMD_FOUND" == false ]]; then/,/fi/ {
           /echo -e "\\\\033\[36mWould you like to execute it? (Yes\/No)\\\\033\[0m"/d
           /read run_answer/d
           /if [[ "$run_answer" =~ ^[Yy](es)?$ ]]; then/d
           /fi/d
          }' /usr/local/bin/s-pilot
      - run: cat /usr/local/bin/s-pilot
      - name: test shell-pilot 
        run: |
          export TERM=dumb
          s-pilot p "bonjour je souhaite utiliser localai avec modèle llama et shell-pilot avec cmd:. Comment utiliser Shell-pilot avec commande avec une action localai dans workflows github action ? repond en français." 
      - run: |
          export TERM=dumb
          (echo "cmd:fais ls\ny" && echo "Yes" && echo "Yes" && echo "Yes" ) |  s-pilot
      - run: |
          pipx install shelloracle
  #    - run: |
    #      echo "LocalAI" | shor config init
      - name: Greet
        id: greet
        run: |
                input="Génére moi un code complet en js et css dans un seul fichier d'une application web microservice de front seulement de site web de magasin de livre qui fonctionne. les livres ainsi que le back seront dans d'autres microsercive que l'on ne s'occupe pas. ce code demander a une page d'accueil avec tout les livre pour les mettre aux panier et une page panier qui resume les livre au panier. l'apli est très simple mais est utilisable. Repond avec uniquement du code donc pas de bonjour de phrase avant le code ou apres ou explication ou commentaire et tout le code est dans le meme fichier"

                # Define the LocalAI API endpoint
                API_URL="http://localhost:8080/chat/completions"

                # Create a JSON payload using jq to handle special characters
                json_payload=$(jq -n --arg input "$input" '{
                model: "'$MODEL_NAME'",
                messages: [
                    {
                    role: "system",
                    content: "You are a developer who provides code functional without additional explanations or comments"
                    },
                    {
                    role: "user",
                    content: $input
                    }
                ]
                }')

                # Send the request to LocalAI
                response=$(curl -s -X POST $API_URL \
                -H "Content-Type: application/json" \
                -d "$json_payload")

                # Extract the result from the response
                result="$(echo $response | jq -r '.choices[0].message.content')"

                 # Print the result
                 echo "Result:"
                 echo "$result" 
                 temp_file=$(mktemp)
                 printf "%s" "$result" > "$temp_file"
                 mv "$temp_file" result.html                            
                # now the output can be consumed with ${{ steps.greet.outputs.message }} by other steps
                    
      - name: test2
        run: cat result.html
      
