name: build test 4
on: 
  push:
  workflow_dispatch:

env:
  dex: 'docker exec kubectl sh -c'

jobs:
  store-front:
    runs-on: ubuntu-latest
    name: A job to say hello
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3.0.2
        id: changes 
        with: 
          filters: | 
            store-front:
              - 'store-front/**'
      - name: docker build
        if: steps.changes.outputs.store-front == 'true'
        run: docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/store-front-test store-front
      - run: docker image ls
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKER_PASSWORD }}
      - if: steps.changes.outputs.store-front == 'true'
        run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/store-front-test

  product-service:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4.1.7
      - uses: dorny/paths-filter@v3.0.2
        id: changes 
        with: 
          filters: | 
            product-service:
              - 'product-service/**'
      - name: docker build
        if: steps.changes.outputs.product-service == 'true'
        run: docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/product-service-test2 product-service
      - run: docker image ls
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKER_PASSWORD }}
      - if: steps.changes.outputs.product-service == 'true'
        run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/product-service-test2

  setup_k3s:
    runs-on: self-hosted
    steps:
      - name: verif si container k3s-server existe sur win 
        run: docker ps -a | findstr k3s-server 
        id: k3s-server
        continue-on-error: true

      - if: steps.k3s-server.outcome == 'failure'
        name: setup k3s dans docker
        run: |
          docker network create k3s
          docker run -d --name k3s-server --network k3s --privileged --restart=always -p 6443:6443 rancher/k3s:v1.31.0-k3s1 server 

  kubectl:
    runs-on: self-hosted
    needs: setup_k3s
    steps:
      - name: creer fonction dex
        run: function dex {docker exec kubectl sh -c "$($Args -join ' ')"} 

      - name: verif si container kubectl existe sur win
        run: docker ps -a | findstr kubectl 
        id: kubectl
        continue-on-error: true

      - name: setup kubectl
        if: steps.kubectl.outcome == 'failure'
        run: |
          docker run -d -p 80:80 -p 8080:8080 -p 9090:9090 -p 3000:3000 -p 3002:3002 --network k3s --name kubectl alpine sh -c 'sleep infinity'
      
      - name: install kubectl
        run: |
          ${{ env.dex }} apk add kubectl --no-cache 
          ${{ env.dex }} mkdir -p /root/.kube/
        continue-on-error: true 
 
      - name: copie k3s.yaml kubectl
        run: |
          docker cp k3s-server:/etc/rancher/k3s/k3s.yaml .
          docker cp k3s.yaml kubectl:/root/.kube/config

      - name: met ip k3s-server dans une variable et modifie la config kubectl
        run: |
          ${{ env.dex }} 'sed -i "s/127.0.0.1/k3s-server/g" /root/.kube/config'

      - name: verif kubectl
        run: |
          dex 'kubectl get nodes'

  monitoring:
    runs-on: self-hosted
    needs: kubectl
    steps:
      - name: verif si helm est installÃ©
        run: $dex 'helm'
        id: helm
        continue-on-error: true

      - name: installe helm 
        if: steps.helm.outcome == 'failure'
        run: |
          $dex 'wget https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz \
          && tar -zxvf helm-v3.16.3-linux-amd64.tar.gz \
          && mv linux-amd64/helm /usr/local/bin/helm \
          && rm -rf linux-amd64 helm-v3.16.3-linux-amd64.tar.gz'

      - name: install helm apli monitoring
        run: |
          $dex 'helm repo add prometheus-community https://prometheus-community.github.io/helm-charts \
          && helm upgrade --install my-kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 57.0.3 -n monitoring --create-namespace --timeout=35m'
  
      - name: attendre monitoring
        run: |
          $dex 'kubectl wait --for=condition=available deployment --all -n monitoring --timeout=35m'
      
  argocd:
    runs-on: self-hosted
    needs: kubectl
    steps:
      - name: install curl
        run: |
          $dex 'apk add curl --no-cache'

      - name: verif si argocd binaire existe deja
        run: $dex 'argocd'
        id: argocd
        continue-on-error: true
        
      - name: install cli-argocd
        if: steps.argocd.outcome == 'failure'
        run: |
          $dex 'curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/download/v2.13.2/argocd-linux-amd64 \
          && install -m 555 argocd-linux-amd64 /usr/local/bin/argocd \
          && rm argocd-linux-amd64'

      - name: create namespace argocd
        run: |
          $dex 'kubectl get namespace argocd || kubectl create namespace argocd'

      - name: verif si argocd-server est en service
        run: $dex 'kubectl get svc argocd-server -n argocd'
        id: argocd-server
        continue-on-error: true

      - name: Deploys application argocd
        run: | 
          $dex 'kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-cd/refs/tags/v2.13.2/manifests/install.yaml -n argocd --timeout=35m' 

      - name: attendre argocd
        run: |
          $dex 'kubectl wait --for=condition=available deployment --all -n argocd --timeout=35m'

#      - name: load balancing
#        run: |
#          echo '{"spec": {"type": "LoadBalancer"}}' > patch.json
#          kubectl patch svc argocd-server -n argocd --type merge --patch "$(cat patch.json)

      - name: connexion argocd
        if: steps.argocd-server.outcome == 'failure'
        env:
          ip: kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
          mdp: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
        run: |
          $dex 'kubectl port-forward svc/argocd-server -n argocd 80:80 &'
          sleep 10
          $dex 'argocd login 127.0.0.1:80 --username admin --password $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo) --insecure ${{ env.sensible-pas-afficher }}'
        continue-on-error: true
          
      - name: update ArgoCD password
        if: steps.argocd-server.outcome == 'failure'
        env:
          mdp: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
        run: docker exec -it kubectl sh -c 'argocd account update-password --account admin --new-password ${{ secrets.ARGOCD }} --current-password ${{ env.mdp }} ${{ env.sensible-pas-afficher }}'
        continue-on-error: true

  contoso:
    runs-on: self-hosted
    needs: [kubectl, argocd]
    steps:
      - name: Create Contoso namespace
        run: |
          $dex 'kubectl get namespace contoso || kubectl create namespace contoso'
      
      - name: connexion argocd
        env:
            ip: kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
            mdp: kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo
        run: |
            $dex 'kubectl port-forward svc/argocd-server -n argocd 80:80 &'
            sleep 5
            $dex 'argocd login 127.0.0.1:80 --username admin --password ${{ secrets.ARGOCD }} --insecure ${{ env.sensible-pas-afficher }}'
        
      - name: Create Application Contoso with Argocd avec namespace
        run: $dex 'argocd app create contoso --repo https://github.com/MelkiBenjamin/deploiement-apli-kubernetes-argocd --path ecommerce --dest-server https://kubernetes.default.svc --dest-namespace contoso --sync-policy automated --auto-prune'

