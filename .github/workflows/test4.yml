name: build test 4
on: 
  push:
#  workflow_dispatch:

env:
  dex: docker exec kubectl /bin/sh -c

jobs:
  store-front:
    runs-on: ubuntu-latest
    name: A job to say hello
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3.0.2
        id: changes 
        with: 
          filters: | 
            store-front:
              - 'store-front/**'
      - name: docker build
        if: steps.changes.outputs.store-front == 'true'
        run: docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/store-front-test store-front
      - run: docker image ls
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKER_PASSWORD }}
      - if: steps.changes.outputs.store-front == 'true'
        run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/store-front-test

  product-service:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4.1.7
      - uses: dorny/paths-filter@v3.0.2
        id: changes 
        with: 
          filters: | 
            product-service:
              - 'product-service/**'
      - name: docker build
        if: steps.changes.outputs.product-service == 'true'
        run: docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/product-service-test2 product-service
      - run: docker image ls
      - run: docker login -u ${{ secrets.DOCKERHUB_USERNAME }} -p ${{ secrets.DOCKER_PASSWORD }}
      - if: steps.changes.outputs.product-service == 'true'
        run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/product-service-test2

  setup_k3s:
    runs-on: self-hosted
    steps:
      - name: verif si container k3s-server existe sur win 
        run: docker ps -a | findstr k3s-server 
        id: k3s-server
        continue-on-error: true

      - if: steps.k3s-server.outcome == 'failure'
        name: setup k3s dans docker pour juste le server pas l'agent
        run: |
          docker network create k3s 
          docker run -d --name k3s-server --network k3s --privileged -v k3s-server:/etc/rancher/k3s -p 6443:6443 rancher/k3s:v1.31.0-k3s1 server --tls-san k3s-server --node-name k3s-server --disable metrics-server
      
  kubectl:
    runs-on: self-hosted
    needs: [setup_k3s]
    steps:
      - name: verif si container kubectl existe sur win
        run: docker ps -a | findstr kubectl 
        id: kubectl
        continue-on-error: true

      - name: setup kubectl
        if: steps.kubectl.outcome == 'failure'
        run: |
          echo "setup kubectl"
          docker run -d -p 80:80 -p 8080:8080 -p 9090:9090 -p 3000:3000 -p 3002:3002 --network k3s -v k3s-server:/root/.kube --name kubectl alpine sh -c 'sleep infinity'
          echo "conteneur kubectl terminer"
        continue-on-error: true

      - name: install kubectl 
        run: >
          ${{ env.dex }} "
          echo Installation de kubectl &&
          apk add kubectl --no-cache &&
          echo kubectl installé avec reussite &&
          echo test kubectl &&
          sleep 5 &&
          ls -alh /root/.kube &&
          echo test kubectl terminer avec reussite &&  
          cp -v /root/.kube/k3s.yaml /root/.kube/config &&
          echo renomage realiser avec reussite"

      - name: modifie la config kubectl 
        run: |
          echo 'Modification du fichier de config kubectl'
          ${{ env.dex }} "sed -i 's/127.0.0.1/k3s-server/g' /root/.kube/config"
          echo 'Modification du fichier de config kubectl terminer avec succes.'

      - name: verif docker kubectl
        run: ${{ env.dex }} 'kubectl get nodes'
          
  monitoring:
    runs-on: self-hosted
    needs: kubectl
    steps:
      - name: verif si helm est installé 
        run: ${{ env.dex }} 'helm'
        id: helm
        continue-on-error: true

      - name: installe helm 
        if: steps.helm.outcome == 'failure'
        run: >
          ${{ env.dex }} "
          wget https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz &&
          tar -zxvf helm-v3.16.3-linux-amd64.tar.gz &&
          mv linux-amd64/helm /usr/local/bin/helm &&
          rm -rf linux-amd64 helm-v3.16.3-linux-amd64.tar.gz"

      - name: install helm apli monitoring
        run: >
          ${{ env.dex }} '
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts &&
          helm upgrade --install my-kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 57.0.3 -n monitoring --create-namespace --timeout=35m'
  
#      - name: attendre monitoring
#        run: |
#          ${{ env.dex }} 'kubectl wait --for=condition=available deployment --all -n monitoring --timeout=20m'
      
  argocd:
    runs-on: self-hosted
    needs: kubectl
    steps:
      - name: install curl
        run: |
          ${{ env.dex }} 'apk add curl --no-cache'

      - name: verif si argocd binaire existe deja
        run: ${{ env.dex }} 'argocd'
        id: argocd
        continue-on-error: true
        
      - name: install cli-argocd
        if: steps.argocd.outcome == 'failure'
        run: >
          ${{ env.dex }} '
          echo telechargement de argocd &&
          curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/download/v2.13.2/argocd-linux-amd64 &&
          echo installation de argocd &&
          install -m 555 argocd-linux-amd64 /usr/local/bin/argocd &&
          echo suppression de argocd-linux-amd64 &&
          rm argocd-linux-amd64'

      - name: create namespace argocd
        run: |
          ${{ env.dex }} 'kubectl get namespace argocd || kubectl create namespace argocd'

      - name: verif si argocd-server est en service
        run: ${{ env.dex }} 'kubectl get svc argocd-server -n argocd'
        id: argocd-server
        continue-on-error: true

      - name: creer secret argocd-initial-admin-secret
        run: |
          ${{ env.dex }} 'kubectl get secret argocd-initial-admin-secret -n argocd || kubectl create secret generic argocd-initial-admin-secret --from-literal=password=${{ secrets.ARGOCD }} -n argocd'

      - name: Deploys application argocd
        run: | 
          ${{ env.dex }} 'kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-cd/refs/tags/v2.13.2/manifests/install.yaml -n argocd' 

      - name: attendre argocd 
        run: |
          ${{ env.dex }} 'kubectl wait --for=condition=ready pod --all -n argocd --timeout=25m'
          ${{ env.dex }} 'kubectl wait --for=condition=available deployment --all -n argocd --timeout=25m'

#      - name: load balancing
#        run: |
#          echo '{"spec": {"type": "LoadBalancer"}}' > patch.json
#          kubectl patch svc argocd-server -n argocd --type merge --patch "$(cat patch.json)

#      - name: port-forward argocd
#        run: ${{ env.dex }} 'nohup kubectl port-forward svc/argocd-server -n argocd 8080:443 &'

      - name: connexion argocd
        if: steps.argocd-server.outcome == 'failure'
        env:
          ip: kubectl get svc argocd-server -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].ip}'
          mdp: $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d; echo)
        run: |
          ${{ env.dex }} 'argocd --port-forward --port-forward-namespace argocd login 127.0.0.1:8080 --username admin --password ${{ secrets.ARGOCD }} --insecure ${{ env.sensible-pas-afficher }}'
          
  contoso:
    runs-on: self-hosted
    needs: [kubectl, argocd]
    steps:
      - name: Create Contoso namespace 
        run: |
          ${{ env.dex }} 'kubectl get namespace contoso || kubectl create namespace contoso'
              
      - name: Create Application Contoso with Argocd avec namespace 
        run: ${{ env.dex }} 'argocd --port-forward --port-forward-namespace argocd app create contoso --repo https://github.com/MelkiBenjamin/deploiement-apli-kubernetes-argocd --path ecommerce --dest-server https://kubernetes.default.svc --dest-namespace contoso --sync-policy automated --auto-prune --t

